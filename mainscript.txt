% This time mainscript contains introductory part
% checking basic backprop implementation on tiny
% dataset 

% if there are problems with plotting...
% graphics_toolkit("gnuplot")

% implement actf & inspect it on a diagram
x = -5:0.1:5;
plot(x, actf(x))
%输出一张图，一条直线
% implement actdf 
% note that input value for actdf is not x itself but actf(x)
plot(x, actdf(actf(x)))

% implement backprop 
% it makes sense to start with a really small dataset
load tiny.txt
tlab = tiny(:,1);
tvec = tiny(:,2:end);
[hlnn olnn] = crann(columns(tvec), 4, 2);
[size(hlnn) size(olnn)]

clsRes = anncls(tvec, hlnn, olnn);
cfmx = confMx(tlab, clsRes);
errcf = compErrors(cfmx)

% It would be very interensting to check the influence of 
%   training set ordering on the speed of training
% What is order of samples in the training set?
% How can we change it to better support our training procedure?

[hlnn olnn terr] = backprop(tvec, tlab, hlnn, olnn, 0.5)
clsRes = anncls(tvec, hlnn, olnn);
cfmx = confMx(tlab, clsRes);
errcf = compErrors(cfmx)

% after reaching 100% classification 
% you can (probably) play with ann_training
